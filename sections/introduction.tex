%% LaTeX2e class for student theses
%% sections/content.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.3.2, 2017-08-01

\chapter{Introduction}
\label{ch:Introduction}

%% -------------------
%% | Example content |
%% -------------------

Software performance is a quality attribute, which determines whether a given system has the ability to perform the functional requirements in terms of acceptable scalability and responsiveness. Many applications crash or cannot be applied because the performance problems have been not taken into account during development. 

In order to avoid performance issues, performance aspects must be captured and treated during system development. Performance tests can be used to decide if the system meets its requirements. However, using it in a huge application can be too expensive because we need to allocate resources and generate measurements of an application, which creates a massive load. 

Performance tests can be altered by performance model prediction, which can reduce the costs of performance tests. A performance model represents an abstraction of the behavior as well as the performance-relevant aspects of the system. Moreover, performance model prediction solves performance problems by using performance models and simulation engines. Performance simulation requires only a fraction of resources to evaluate the performance of a system. Another advantage of model-based performance prediction is the capability of identifying performance issues before implementation, which then helps to correct design problems as early as possible. 

Model-based performance prediction can be used in the modern agile development process to support design decisions and reduce the costs of measurement-based performance evaluation. However, Existing approaches have two shortcomings. (1) they do not extract incrementally the performance model, which means if they will be used iteratively, they will extract the performance model of the whole system in each iteration. This can guide to a high monitoring overhead in case of huge systems. Moreover, extracting the performance model in such way will not keep the old modifications of the performance in each iteration.  (2) the existing techniques do not come up with performance model parameters (like Resource Demands, loop execution number, the probability of selecting a branch) and their dependencies with impacting factors like input data.

There exist approaches that extract incrementally the performance model from the source code and keep them consistent. For example, Langhammer introduced an approach \cite{langhammer2017automated} that keep the source code and architecture consistent include the performance model in term of Service Effect Specification (SEFF) \ref{sec: SEFFs}. Furthermore, Mazkatli and Koziolek have extended his approach by introducing an approach that uses the Continuous Integration (CI) and Continuous Deployment of the source code and extend them with the Continuous Integration of a Performance Model (CIMP) \cite{mazkatli2018continuous}. Both presented approaches require an adaptive monitoring approach that provides them with the required monitoring information and can be integrated into the continuous integration of the performance model. 

In this thesis, we present an approach for adaptive monitoring for continuous performance model integration. Our approach can be used incrementally to provide monitoring information for continuous performance model integration. In particular, we used the performance model of the Palladio Component Model (PCM)(Section \ref{sec:The Palladio Component Model}), which describes the behavior and the performance aspects of the system in term of SEFF. Furthermore, our approach can provide the monitoring information that can be used to estimate the SEFF model parameters. We provide monitoring information of computation response time, loop execution number, the probability of selecting a branch and the parameters of service calls, which can be used to consider the parametric dependencies in SEFF model parameters estimation.

In order to achieve incremental instrumentation of the source code, our approach uses the change-driven framework Vitruvius (Section \ref{sec:Vitruvius}) and we extended the Coevolution approach \cite{langhammer2017automated} of Langhammer. Vitruvius provides the possibility to keep model instances consistent via consistency preservation rules can be defined by the user. Moreover, Langhammer used Vitruvius to generate incrementally SEFF models, but he did not provide an adaptive monitoring approach to provide SEFF Models with the required monitoring information. Moreover, we contributed to Vitruvius by presenting an Instrumentation Model (IM) (Section \ref{sec:Adaptive Instrumentation}), which describes the instrumentation points, which are needed for the source code instrumentation. Then, we defined the consistency preservation rules that keep the source code model and IM consistent. Using Vitruvius, we could in each iteration capture changes in the source code and create accordingly the instrumentation points. Therefore, we could instrument the source code incrementally. 

Our approach is part of the vision presented by Mazkatli and Koziolek \cite{mazkatli2018continuous}. They extended the agile development process by introducing an approach that automatically and continuously integrates the performance model. 

In chapter \ref{ch:Foundations} we explain the foundation of our approach. In chapter \ref{ch:Thesis Statement} we define our contributions. In chapter \ref{ch:Adaptive Monitoring for Continuous Performance Model Integration} we describe our approach. In chapter \ref{ch:Evaluation} we a case study to evaluate out approach. In chapter \ref{ch:Related Work} we discuss the related work. Chapter \ref{ch:Conclusions and Future Work} gives a summary of this thesis and feature work. 

